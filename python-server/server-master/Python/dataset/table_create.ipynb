{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   NumChickens FieldArea ItemSurfaceArea  Unnamed: 3       Radius  \\\n",
      "0           21  17777,78           49,25         NaN   0,80000005   \n",
      "1           25  20069,44           49,25         NaN  0,849999906   \n",
      "2           37     22500           49,25         NaN          0,9   \n",
      "\n",
      "          Size   ASB  Unnamed: 7  Unnamed: 8  Unnamed: 9  ...  Unnamed: 16  \\\n",
      "0  4,000165622  0,85         NaN         NaN         NaN  ...          NaN   \n",
      "1  4,000165622  0,85         NaN         NaN         NaN  ...          NaN   \n",
      "2  4,000165622  0,85         NaN         NaN         NaN  ...          NaN   \n",
      "\n",
      "   Unnamed: 17  Unnamed: 18  Unnamed: 19  Unnamed: 20  Unnamed: 21  \\\n",
      "0          NaN          NaN          NaN          NaN          NaN   \n",
      "1          NaN          NaN          NaN          NaN          NaN   \n",
      "2          NaN          NaN          NaN          NaN          NaN   \n",
      "\n",
      "   Unnamed: 22  Unnamed: 23  Unnamed: 24  Unnamed: 25  \n",
      "0          NaN          NaN          NaN          NaN  \n",
      "1          NaN          NaN          NaN          NaN  \n",
      "2          NaN          NaN          NaN          NaN  \n",
      "\n",
      "[3 rows x 26 columns]\n"
     ]
    }
   ],
   "source": [
    "import pandas\n",
    "import itertools as it\n",
    "\n",
    "DS_FOR_KIDS = True\n",
    "\n",
    "\n",
    "if DS_FOR_KIDS:\n",
    "    lookup_table = pandas.read_csv(\"./legacy/valid_values_kids.csv\", sep=\";\")\n",
    "else:\n",
    "    lookup_table = pandas.read_csv(\"./legacy/valid_values.csv\", sep = \";\")\n",
    "\n",
    "print(lookup_table[0:3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lookup_table.reset_index()\n",
    "for i, data in lookup_table.iterrows():\n",
    "    if i > 0:\n",
    "        break\n",
    "    print(i)\n",
    "    #print(data)\n",
    "    print(data[1].replace(\",\", \".\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import TruncatedSVD\n",
    "from sklearn.decomposition import PCA\n",
    "import numpy as np\n",
    "from typing import Tuple, List\n",
    "\n",
    "def get_PCA_pars(valid_values: pandas.DataFrame) -> Tuple[TruncatedSVD, np.ndarray]:\n",
    "    pars = []\n",
    "    j=0\n",
    "    for i,t in valid_values.iterrows():\n",
    "        pars.append([float(t[1].replace(\",\", \".\")), float(t[2].replace(\",\", \".\"))])\n",
    "        j=i\n",
    "    pars = np.array(pars)\n",
    "\n",
    "    #print(i)\n",
    "    mean = pars.mean(axis=0)\n",
    "    #print(mean)\n",
    "    pars = pars/mean\n",
    "    pca = TruncatedSVD(n_components=1)\n",
    "\n",
    "    pca.fit(pars)\n",
    "\n",
    "    return pca, mean\n",
    "\n",
    "def compute_ND_NND(pca: TruncatedSVD, mean:np.ndarray, t_right: List[float], t_left: List[float]) -> Tuple[float, float]:\n",
    "    n_right = t_right[0]\n",
    "    n_left = t_left[0]\n",
    "\n",
    "    t_right_np = np.array([[t_right[1], t_right[2]]])/mean\n",
    "    t_left_np = np.array([[t_left[1], t_left[2]]])/mean\n",
    "\n",
    "    #print(t_right_np)\n",
    "\n",
    "    sd_right = pca.transform(t_right_np)[0][0]\n",
    "    sd_left = pca.transform(t_left_np)[0][0]\n",
    "\n",
    "\n",
    "    return np.log(n_right/n_left), np.log(sd_right/sd_left) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "data = {}\n",
    "columns = [\"Unnamed\",\"NumLeft\",\"FieldAreaLeft\",\"ItemSurfaceAreaLeft\",\"NumRight\",\"FieldAreaRight\",\"ItemSurfaceAreaRight\",\"Ratio L/R\",\"LogRatio\",\"Log - Normalized\",\"Difficulty Coefficient\",\"Diff_coeff_filtering\", \"nd_LogRatio\", \"nnd_LogRatio\"]\n",
    "pca, mean = get_PCA_pars(lookup_table)\n",
    "for c in columns:\n",
    "    data[c] = []\n",
    "i=0\n",
    "for (ileft, dleft), (iright,dright) in it.combinations(lookup_table.iterrows(), 2):\n",
    "    if dleft[0] == dright[0]:\n",
    "        continue\n",
    "    #print(dleft)\n",
    "    fAreaLeft = float(dleft[1].replace(\",\", \".\"))\n",
    "    fAreaRight = float(dright[1].replace(\",\", \".\"))\n",
    "    iAreaLeft = float(dleft[2].replace(\",\", \".\"))\n",
    "    iAreaRight = float(dright[2].replace(\",\", \".\"))\n",
    "\n",
    "    data[\"Unnamed\"].append(i) \n",
    "    data[\"NumLeft\"].append(dleft[0])\n",
    "    data[\"FieldAreaLeft\"].append(fAreaLeft)\n",
    "    data[\"ItemSurfaceAreaLeft\"].append(iAreaLeft)\n",
    "    data[\"NumRight\"].append(dright[0])\n",
    "    data[\"FieldAreaRight\"].append(fAreaRight)\n",
    "    data[\"ItemSurfaceAreaRight\"].append(iAreaRight)\n",
    "\n",
    "    #nd and nnd coords, should be relevant for any kind of implemented ai \n",
    "    nd_logratio, nnd_logratio = compute_ND_NND(pca, mean,[int(dleft[0]), fAreaLeft,iAreaLeft], [int(dright[0]), fAreaRight, iAreaRight])\n",
    "    data[\"nd_LogRatio\"].append(nd_logratio)\n",
    "    data[\"nnd_LogRatio\"].append(nnd_logratio)\n",
    "\n",
    "    #old statistics, computed for backward compatibility\n",
    "    data[\"Ratio L/R\"].append(round((dleft[0]/dright[0]),2))\n",
    "    data[\"LogRatio\"].append(round(np.log10(round((dleft[0]/dright[0]),2)),2))\n",
    "    data[\"Log - Normalized\"].append(round(np.log10(round((dleft[0]/dright[0]),2)),2))\n",
    "    data[\"Difficulty Coefficient\"].append(round(random.uniform(0, 1), 2))\n",
    "    data[\"Diff_coeff_filtering\"].append(round(random.uniform(0,1), 2))\n",
    "\n",
    "\n",
    "    #do the same for the specular trial\n",
    "    data[\"Unnamed\"].append(i) \n",
    "    data[\"NumLeft\"].append(dright[0])\n",
    "    data[\"FieldAreaLeft\"].append(fAreaRight)\n",
    "    data[\"ItemSurfaceAreaLeft\"].append(iAreaRight)\n",
    "    data[\"NumRight\"].append(dleft[0])\n",
    "    data[\"FieldAreaRight\"].append(fAreaLeft)\n",
    "    data[\"ItemSurfaceAreaRight\"].append(iAreaLeft)\n",
    "\n",
    "    #nd and nnd coords, should be relevant for any kind of implemented ai \n",
    "    nd_logratio, nnd_logratio = compute_ND_NND(pca,mean,[int(dright[0]), fAreaRight,iAreaRight], [int(dleft[0]), fAreaLeft, iAreaLeft])\n",
    "    data[\"nd_LogRatio\"].append(nd_logratio)\n",
    "    data[\"nnd_LogRatio\"].append(nnd_logratio)\n",
    "\n",
    "    #old statistics, computed for backward compatibility\n",
    "    data[\"Ratio L/R\"].append(round((dright[0]/dleft[0]),2))\n",
    "    data[\"LogRatio\"].append(round(np.log10(round((dright[0]/dleft[0]),2)),2))\n",
    "    data[\"Log - Normalized\"].append(round(np.log10(round((dright[0]/dleft[0]),2)),2))\n",
    "    data[\"Difficulty Coefficient\"].append(round(random.uniform(0, 1), 2))\n",
    "    data[\"Diff_coeff_filtering\"].append(round(random.uniform(0,1), 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "new_table = pandas.DataFrame(data = data, columns=columns)\n",
    "\n",
    "# additional processing for backward compatibility\n",
    "def diff_coef(i, x, y):\n",
    "    try:\n",
    "        if (x > 0 and y >= 0) or (x < 0 and y <= 0):\n",
    "            k = math.atan(y/x)\n",
    "        elif (x < 0 and y >= 0) or (x > 0 and y <= 0):\n",
    "            k = math.pi - abs(math.atan(y/x))\n",
    "        a = math.degrees(abs((math.pi/4)-k))\n",
    "    except:\n",
    "        return -1\n",
    "    return a\n",
    "\n",
    "#i think it's wrong normalizing and making decisions on normalized values,\n",
    "#adding new trials can change the whole feature space, we are losing coherency with respect to Learning to Focus on Numbers\n",
    "new_table[\"Log - Normalized\"] = round(new_table[\"Log - Normalized\"]/new_table[\"Log - Normalized\"].max(),2).abs()\n",
    "new_table[\"Difficulty Coefficient\"] = round(1- new_table[\"Log - Normalized\"],2)\n",
    "\n",
    "max_nd = new_table['nd_LogRatio'].abs().max()\n",
    "max_nnd = new_table['nnd_LogRatio'].abs().max()\n",
    "\n",
    "filtering_diff = []\n",
    "for i, row in new_table.iterrows():\n",
    "    filtering_diff.append(diff_coef(i,row[\"nd_LogRatio\"]/max_nd, row[\"nnd_LogRatio\"]/max_nnd))\n",
    "\n",
    "new_table[\"Diff_coeff_filtering\"] = filtering_diff\n",
    "new_table[\"Diff_coeff_filtering\"] = new_table[\"Diff_coeff_filtering\"]/new_table[\"Diff_coeff_filtering\"].max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "if DS_FOR_KIDS:\n",
    "    if os.path.exists(\"lookup_table_kids.csv\"):\n",
    "        os.remove(\"lookup_table_kids.csv\")\n",
    "    new_table.to_csv(\"./lookup_table_kids.csv\")\n",
    "else:\n",
    "    if os.path.exists(\"lookup_table.csv\"):\n",
    "        os.remove(\"lookup_table.csv\")\n",
    "    new_table.to_csv(\"./lookup_table.csv\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Some analysis and ad hoc computations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas\n",
    "lookup_table = pandas.read_csv(\"./lookup_table.csv\")\n",
    "\n",
    "print(lookup_table['nd_LogRatio'].min())\n",
    "print(lookup_table['nd_LogRatio'].max())\n",
    "print(lookup_table['nnd_LogRatio'].min())\n",
    "print(lookup_table['nnd_LogRatio'].max())\n",
    "#highest = lookup_table.iloc((lookup_table['nd_LogRatio']).abs().argsort()[:1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "okay = False\n",
    "count = 0\n",
    "count_two=0\n",
    "for row in lookup_table.iterrows():\n",
    "    row=row[1]\n",
    "    if row[\"nd_LogRatio\"] >0 and row[\"nnd_LogRatio\"]<0:\n",
    "        #print(row)\n",
    "        okay = True\n",
    "        #assert False == True\n",
    "        count+=1\n",
    "    if row[\"nd_LogRatio\"] <0 and row[\"nnd_LogRatio\"]>0:\n",
    "        count_two +=1\n",
    "\n",
    "print(okay)\n",
    "print(count)\n",
    "print(count_two)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_nd = lookup_table['nd_LogRatio'].abs().max()\n",
    "max_nnd = lookup_table['nnd_LogRatio'].abs().max()\n",
    "\n",
    "lookup_table['nd_LogRatio'] = lookup_table['nd_LogRatio'].abs()/max_nd\n",
    "lookup_table['nnd_LogRatio'] = lookup_table['nnd_LogRatio'].abs()/max_nnd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "def myHistogram(data: np.ndarray,n_labels:int,labels:np.ndarray, bins: int=20):\n",
    "    colors = [\"red\", \"green\", \"blue\",\"orange\" , \"gray\", \"orange\"]\n",
    "\n",
    "    for i in range(0,data.shape[0]):\n",
    "        for j in range(0,n_labels):\n",
    "            plt.hist(data[i, labels == j],bins=bins, density=True, color=colors[j],alpha=0.6, histtype='bar', rwidth=0.9)\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nd_logratio = lookup_table[\"nd_LogRatio\"]\n",
    "nnd_logratio = lookup_table[\"nnd_LogRatio\"]\n",
    "\n",
    "nd =plt.hist(nd_logratio, color=\"red\", histtype='bar', alpha=0.6)\n",
    "nnd =plt.hist(nnd_logratio, color = \"green\",  histtype='bar', alpha=0.6)\n",
    "\n",
    "plt.legend([\"Numerical Dimension\", [\"Non Numerical Dimension\"]])\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas\n",
    "import math\n",
    "def diff_coeff(i, x, y):\n",
    "    \n",
    "    if (x > 0 and y >= 0) or (x < 0 and y <= 0):\n",
    "            k = math.atan(y/x)\n",
    "    elif (x < 0 and y >= 0) or (x > 0 and y <= 0):\n",
    "        k = math.pi - abs(math.atan(y/x))\n",
    "    a = math.degrees(abs((math.pi/4)-k))\n",
    "    \n",
    "    return a\n",
    "\n",
    "new_table = pandas.read_csv(\"./lookup_table.csv\")\n",
    "\n",
    "max_nd = new_table['nd_LogRatio'].abs().max()\n",
    "max_nnd = new_table['nnd_LogRatio'].abs().max()\n",
    "print(diff_coeff(1, 0.3, 0.2))\n",
    "print(diff_coeff(1, -0.3, 0.2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from typing import List, Any, Callable\n",
    "\n",
    "def to_mock_trial(nd: float, nnd: float):\n",
    "    return [-1,-1,-1,-1,-1,-1,-1,-1,nd, nnd]\n",
    "\n",
    "def plot_trials(boundary_vector: np.ndarray, trials: List[List[Any]], corrects: List[bool], annotations: List[float], ann_str: bool = False, plot_stats: Callable = None, plot_dist: bool = False):\n",
    "\n",
    "    fig, ax= plt.subplots(1,1)\n",
    "    #ax = fig.axes\n",
    "    \n",
    "    vec= 5*boundary_vector\n",
    "    \n",
    "    plt.plot([vec[0], -vec[0]], [vec[1], -vec[1]])\n",
    "\n",
    "    colors = {True: 'green', False: 'red'}\n",
    "\n",
    "    coords = list(map(lambda x: x[8:],trials))\n",
    "    \n",
    "    \n",
    "    for i, coord in enumerate(coords):\n",
    "        #print(corrects[i])\n",
    "        plt.scatter(coord[0], coord[1], color = colors[corrects[i]])\n",
    "        #ax.text(coord[0]-0.1, coord[1]+0.1, str(round(times[i],2)), color = colors[corrects[i]])\n",
    "\n",
    "        if ann_str:\n",
    "            plt.annotate(annotations[i], (coord[0], coord[1]), color= \"red\")\n",
    "        else:    \n",
    "            ax.annotate(str(round(annotations[i],2)), (coord[0], coord[1]), color=\"red\")\n",
    "        #print(f\">>{coord}\")\n",
    "        if plot_dist:\n",
    "            coord = np.array(coord)\n",
    "            proj = np.dot(boundary_vector, coord)\n",
    "            proj = boundary_vector*proj\n",
    "            ax.plot([proj[0], coord[0]], [proj[1], coord[1]], color=\"red\")\n",
    "        \n",
    "    if plot_stats is not None:\n",
    "        plot_stats(plt)\n",
    "\n",
    "    ax.spines['left'].set_position('zero')\n",
    "    ax.spines['right'].set_color('none')\n",
    "    ax.spines['bottom'].set_position('zero')\n",
    "    ax.spines['top'].set_color('none')\n",
    "\n",
    "    plt.xlim([-1, 1])\n",
    "    plt.ylim([-1,1])\n",
    "    #fig.supxlabel(\"Numerical dimension\", loc=\"left\")\n",
    "    #fig.supylabel(\"Non numerical dimension\", loc=\"bottom\")\n",
    "    plt.grid(True)\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "def unit_vector(vector):\n",
    "    \"\"\" Returns the unit vector of the vector.  \"\"\"\n",
    "    return vector / np.linalg.norm(vector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas\n",
    "import math\n",
    "#from ..AI.ai_plot import plot_trials\n",
    "\n",
    "lookup_table = pandas.read_csv(\"./lookup_table.csv\")\n",
    "\n",
    "max_nd = lookup_table['nd_LogRatio'].abs().max()\n",
    "max_nnd = lookup_table['nnd_LogRatio'].abs().max()\n",
    "\n",
    "col = \"Diff_coeff_filtering\"\n",
    "fetched_samples = 1\n",
    "\n",
    "target_main_diff = 0.95\n",
    "hard = lookup_table.iloc[(lookup_table[col]-target_main_diff).abs().argsort()[:fetched_samples]]\n",
    "\n",
    "target_main_diff = 0.01\n",
    "easy = lookup_table.iloc[(lookup_table[col]-target_main_diff).abs().argsort()[:fetched_samples]]\n",
    "\n",
    "hard_diff = round(float(hard[col]),2)\n",
    "easy_diff = round(float(easy[col]),2) \n",
    "\n",
    "hard = to_mock_trial(float(hard['nd_LogRatio'])/max_nd, float(hard['nnd_LogRatio'])/max_nnd)\n",
    "easy = to_mock_trial(float(easy['nd_LogRatio'])/max_nd, float(easy['nnd_LogRatio'])/max_nnd)\n",
    "\n",
    "\n",
    "print(hard)\n",
    "print(easy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trials = [hard, easy]\n",
    "\n",
    "corrects = [True, True]\n",
    "anns = [f\"fd - {hard_diff}\", f\"fd - {easy_diff}\"]\n",
    "\n",
    "plot_trials([1, 1], trials, corrects, anns, ann_str=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "col = \"Difficulty Coefficient\"\n",
    "fetched_samples = 1\n",
    "\n",
    "x = np.linspace(0.2, 0.8, 5)\n",
    "\n",
    "trials = []\n",
    "corrects = []\n",
    "anns = []\n",
    "\n",
    "for sd in x:\n",
    "    target_main_diff = sd\n",
    "    trial = lookup_table.iloc[(lookup_table[col]-target_main_diff).abs().argsort()[:fetched_samples]]\n",
    "    diff = round(float(trial[col]),2)\n",
    "\n",
    "    trials.append(to_mock_trial(float(trial['nd_LogRatio'])/max_nd, float(trial['nnd_LogRatio'])/max_nnd))\n",
    "    corrects.append(True)\n",
    "    anns.append(f\"sd - {round(float(trial[col]),2) }\")\n",
    "\n",
    "print(easy)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.1"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "cef666fe899b9fb0a0eef44b04aee0b96e2cf67f4acde4cc6010a5fee1e2a40c"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
